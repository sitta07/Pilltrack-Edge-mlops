import os
import sys
import json
import hashlib
import yaml
from dotenv import load_dotenv

# Add path to find src modules
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

load_dotenv()

# Import s3_helper (à¸•à¹‰à¸­à¸‡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸™à¸µà¹‰à¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¹à¸¥à¸° import à¹„à¸”à¹‰)
try:
    from utils.s3_helper import upload_to_s3
except ImportError:
    print("âŒ Critical Error: Cannot import 'upload_to_s3' from src.utils.s3_helper")
    sys.exit(1)

def load_params(param_path="params.yaml"):
    with open(param_path, "r") as f: return yaml.safe_load(f)

def calculate_md5(file_path):
    """à¸ªà¸£à¹‰à¸²à¸‡ MD5 Hash à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹à¸›à¸°à¹ƒà¸™ Metadata"""
    if not os.path.exists(file_path): return None
    with open(file_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def main():
    print("ğŸš€ Starting Deployment Stage...")
    
    # à¹€à¸Šà¹‡à¸ Environment Variable à¸à¹ˆà¸­à¸™à¹€à¸¥à¸¢
    TARGET_BUCKET = os.getenv("S3_BUCKET_NAME")
    if not TARGET_BUCKET:
        print("âŒ Error: 'S3_BUCKET_NAME' env var is missing!")
        sys.exit(1)

    params = load_params()
    
    # à¸à¸³à¸«à¸™à¸” Path
    MODEL_PATH = "models/student_quant_int8.tflite" # à¸«à¸£à¸·à¸­à¸­à¹ˆà¸²à¸™à¸ˆà¸²à¸ params à¸à¹‡à¹„à¸”à¹‰
    INDEX_PATH = params['enrollment']['index_file']
    LABELS_PATH = params['enrollment']['labels_file']
    META_PATH = params['enrollment']['metadata_file']
    S3_PREFIX = params['enrollment']['s3_prefix']

    # 1. Generate Metadata (à¸—à¸³à¸ªà¸”à¹† à¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡)
    print("ğŸ“ Generating Deployment Metadata...")
    metadata = {
        "version": "v1-auto-deploy", # à¸­à¸²à¸ˆà¸ˆà¸°à¸£à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸²à¸ GitHub SHA à¸à¹‡à¹„à¸”à¹‰à¸–à¹‰à¸²à¸­à¸¢à¸²à¸ Advance
        "bucket": TARGET_BUCKET,
        "files": {
            "student_model.tflite": calculate_md5(MODEL_PATH),
            "pill_db.index": calculate_md5(INDEX_PATH),
            "labels.json": calculate_md5(LABELS_PATH),
        }
    }
    
    # Save Metadata à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¸à¹ˆà¸­à¸™
    with open(META_PATH, "w") as f:
        json.dump(metadata, f, indent=2)

    # 2. List à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¸­à¸‡à¸—à¸µà¹ˆà¸ˆà¸°à¸ªà¹ˆà¸‡
    files_to_upload = {
        MODEL_PATH: "student_model.tflite",
        INDEX_PATH: "pill_db.index",
        LABELS_PATH: "labels.json",
        META_PATH: "model_metadata.json"
    }

    # 3. Upload Loop
    print(f"â˜ï¸ Uploading artifacts to S3 Bucket: {TARGET_BUCKET}...")
    success_count = 0
    
    for local_path, s3_filename in files_to_upload.items():
        if os.path.exists(local_path):
            s3_dest = f"{S3_PREFIX}{s3_filename}"
            print(f"   Process: {local_path} -> {s3_dest}")
            
            if upload_to_s3(local_path, s3_dest, bucket_name=TARGET_BUCKET):
                print(f"   âœ… Uploaded: {s3_filename}")
                success_count += 1
            else:
                print(f"   âŒ Failed to upload: {s3_filename}")
        else:
            print(f"   âš ï¸ File not found (Skipping): {local_path}")

    # 4. Summary
    total_files = len(files_to_upload)
    if success_count == total_files:
        print("\nğŸ‰ğŸ‰ Deployment Successful! All files are on S3. ğŸ‰ğŸ‰")
        sys.exit(0)
    else:
        print(f"\nâš ï¸ Deployment Incomplete! ({success_count}/{total_files} files uploaded)")
        sys.exit(1)

if __name__ == "__main__":
    main()