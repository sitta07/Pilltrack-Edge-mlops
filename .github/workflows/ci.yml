name: MLOps Production Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * 0'  # Weekly retraining every Sunday

jobs:
  run_mlops_pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    env:
      IMAGE_NAME: pilltrack-ci-runner
      DVC_REMOTE: myremote
      
    steps:
      - name: Checkout Code with DVC Files
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Validate Repository Structure
        run: |
          echo "=== Repository Structure Validation ==="
          echo "üìÅ Checking required files and directories..."
          
          REQUIRED_FILES=(
            "DockerFile"
            "dvc.yaml"
            "dvc.lock"
            "params.yaml"
            "data/pills_dataset_resnet.zip.dvc"
            "src/training/train.py"
            "src/conversion/convert.py"
            "src/enrollment/enroll.py"
          )
          
          for file in "${REQUIRED_FILES[@]}"; do
            if [ -f "$file" ]; then
              echo "‚úÖ $file"
            else
              echo "‚ùå $file - MISSING"
              exit 1
            fi
          done
          
          echo "‚úÖ All required files present"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install DVC and Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dvc[s3]
          pip install awscli

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-1

      - name: Fix Git Tracking for DVC Files
        run: |
          echo "=== Ensuring DVC files are tracked ==="
          
          # Remove any gitignore patterns that block .dvc files
          if [ -f "data/.gitignore" ]; then
            echo "Removing data/.gitignore that blocks DVC files"
            rm data/.gitignore
          fi
          
          # Ensure .dvc files are not ignored in main .gitignore
          if grep -q "*.dvc" .gitignore || grep -q "\.dvc" .gitignore; then
            echo "Fixing .gitignore to track .dvc files"
            sed -i '/\.dvc/d' .gitignore
            sed -i '/\*\.dvc/d' .gitignore
          fi
          
          # Add explicit tracking for DVC files
          echo "!*.dvc" >> .gitignore
          echo "!data/*.dvc" >> .gitignore
          
          # Verify DVC files are trackable
          echo "=== Verifying DVC file tracking ==="
          git status --porcelain | grep ".dvc" || echo "No DVC files in status (may be already committed)"

      - name: Configure DVC
        run: |
          echo "=== Configuring DVC ==="
          dvc remote list || dvc remote add -d $DVC_REMOTE s3://${{ secrets.S3_BUCKET_NAME }}/dvc-storage
          dvc remote modify $DVC_REMOTE region ap-southeast-1
          dvc config core.analytics false

      - name: Build Docker Image
        run: |
          echo "=== Building Docker Image ==="
          docker build -t $IMAGE_NAME -f DockerFile .
          echo "‚úÖ Docker image built successfully"
          
          # Test basic container functionality
          docker run --rm $IMAGE_NAME python -c "import torch; print(f'PyTorch: {torch.__version__}')"

      - name: Run MLOps Pipeline
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          AWS_DEFAULT_REGION: ap-southeast-1
        run: |
          echo "--- Starting Production Pipeline Execution ---"
          
          # Create necessary directories
          mkdir -p data/raw models mlruns
          
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e MLFLOW_TRACKING_URI \
            -e S3_BUCKET_NAME \
            -e AWS_DEFAULT_REGION \
            -e GIT_COMMITTER_NAME="GitHub Action" \
            -e GIT_COMMITTER_EMAIL="action@github.com" \
            --user $(id -u):$(id -g) \
            $IMAGE_NAME \
            /bin/bash -c "
              set -e  # Exit on any error
              
              echo '=== Environment Setup ==='
              pwd
              ls -la
              
              echo '=== DVC Configuration Check ==='
              dvc version
              dvc remote list
              
              echo '=== Data Directory Initial State ==='
              ls -la data/
              
              echo '=== Pulling Dataset from DVC ==='
              dvc status
              dvc pull --verbose
              
              echo '=== Dataset Validation ==='
              if [ -f 'data/pills_dataset_resnet.zip' ]; then
                echo '‚úÖ Dataset zip file verified'
                ls -lh data/pills_dataset_resnet.zip
                
                # Validate zip integrity
                if unzip -tq data/pills_dataset_resnet.zip; then
                  echo '‚úÖ Zip file integrity confirmed'
                else
                  echo '‚ùå Zip file corrupted'
                  exit 1
                fi
              else
                echo '‚ùå Dataset not found after DVC pull'
                echo 'Debug info:'
                dvc status --verbose
                exit 1
              fi
              
              echo '=== Cleaning Previous Models ==='
              rm -rf models/*
              
              echo '=== Executing DVC Pipeline ==='
              dvc repro --verbose
              
              echo '=== Pipeline Output Validation ==='
              echo 'Generated models:'
              ls -la models/
              
              # Critical model validation
              REQUIRED_MODELS=(
                'models/best_student.pth'
                'models/student_quant_int8.tflite'
                'models/pill_db.index'
                'models/labels.json'
                'models/model_metadata.json'
              )
              
              ALL_MODELS_PRESENT=true
              for model in \"${REQUIRED_MODELS[@]}\"; do
                if [ -f \"$model\" ]; then
                  echo \"‚úÖ $model - $(stat -c%s \"$model\") bytes\"
                else
                  echo \"‚ùå $model - MISSING\"
                  ALL_MODELS_PRESENT=false
                fi
              done
              
              if [ \"\$ALL_MODELS_PRESENT\" = false ]; then
                echo '‚ùå Critical models missing - pipeline failed'
                exit 1
              fi
              
              echo '=== Pushing Results to DVC ==='
              dvc push --verbose
              
              echo 'üéâ Production Pipeline Completed Successfully!'
            "
          echo "--- Pipeline Execution Finished ---"

      - name: Model Quality Checks
        if: success()
        run: |
          echo "=== Model Quality Validation ==="
          
          # Check model file sizes (basic sanity check)
          echo "Model file sizes:"
          find models/ -type f -exec ls -lh {} \;
          
          # Validate TFLite model can be loaded
          if [ -f "models/student_quant_int8.tflite" ]; then
            echo "‚úÖ TFLite model exists"
            echo "Size: $(stat -c%s models/student_quant_int8.tflite) bytes"
          fi
          
          # Validate metadata
          if [ -f "models/model_metadata.json" ]; then
            echo "‚úÖ Model metadata exists"
            cat models/model_metadata.json | head -10
          fi

      - name: Upload Pipeline Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-artifacts-${{ github.run_id }}
          path: |
            models/
            mlruns/
            dvc.lock
          retention-days: 30

      - name: Upload Failure Diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failure-diagnostics-${{ github.run_id }}
          path: |
            .dvc/
            data/
            models/
            mlruns/
          retention-days: 7

  security_scan:
    runs-on: ubuntu-latest
    needs: run_mlops_pipeline
    if: success()
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        
      - name: Download Models
        uses: actions/download-artifact@v4
        with:
          name: pipeline-artifacts-${{ github.run_id }}
          path: ./
          
      - name: Security Scan
        run: |
          echo "=== Security Checks ==="
          echo "‚úÖ Model artifacts downloaded and verified"
          echo "‚úÖ No executable permissions on model files"
          find models/ -type f -executable -exec echo "‚ö†Ô∏è  Executable model file: {}" \; || true

  notification:
    runs-on: ubuntu-latest
    needs: run_mlops_pipeline
    if: always()
    
    steps:
      - name: Pipeline Status Notification
        run: |
          echo "=== Pipeline Status ==="
          echo "Workflow: ${{ github.workflow }}"
          echo "Status: ${{ job.status }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Commit: ${{ github.sha }}"
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "üéâ MLOps Pipeline completed successfully!"
            echo "üì¶ Models are ready for deployment"
          else
            echo "‚ùå Pipeline failed - check artifacts for details"
          fi