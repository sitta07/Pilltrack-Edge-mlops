name: MLOps Production Pipeline (Train, Convert, Deploy)

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  run_full_mlops_pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    env:
      IMAGE_NAME: pilltrack-ci-runner
      
    steps:
      - name: Checkout Repository Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # ดึง history ทั้งหมดสำหรับ DVC

      - name: Setup DVC
        uses: iterative/setup-dvc@v1
        with:
          version: 3.0.0

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-1

      - name: Build MLOps Environment Container
        run: |
          docker build -t $IMAGE_NAME -f DockerFile .
          echo "✅ Docker image built successfully"

      - name: Run DVC Repro Pipeline
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          AWS_DEFAULT_REGION: ap-southeast-1 
        run: |
          echo "--- Starting Pipeline Execution inside Docker ---"
          
          # สร้างโฟลเดอร์ necessary ก่อน
          mkdir -p data/raw models mlruns
          
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e MLFLOW_TRACKING_URI \
            -e S3_BUCKET_NAME \
            -e AWS_DEFAULT_REGION \
            --user $(id -u):$(id -g) \
            $IMAGE_NAME \
            /bin/bash -c "
              set -e  # Exit on error
              
              echo '=== Current Directory Structure ==='
              pwd
              ls -la
              
              echo '=== Checking DVC Configuration ==='
              dvc version
              dvc remote list || echo 'No DVC remotes configured'
              
              echo '=== Available DVC Files ==='
              find . -name '*.dvc' -type f | head -10
              
              echo '=== Data Directory Before DVC Pull ==='
              ls -la data/ || echo 'data/ directory not found'
              
              echo '=== Pulling Data from DVC Remote ==='
              dvc pull -v
              
              echo '=== Data Directory After DVC Pull ==='
              ls -la data/
              if [ -f 'data/pills_dataset_resnet.zip' ]; then
                echo '✅ Dataset zip file found'
                ls -lh data/pills_dataset_resnet.zip
              else
                echo '❌ Dataset zip file missing!'
                echo 'Files in data/:'
                ls -la data/
                exit 1
              fi
              
              echo '=== Running DVC Pipeline ==='
              dvc status
              dvc repro -v
              
              echo '=== Checking Pipeline Outputs ==='
              echo 'Models generated:'
              ls -la models/ || echo 'models/ directory not found'
              
              echo '=== Pushing Results to DVC Remote ==='
              dvc push -v
              
              echo '✅ Pipeline completed successfully!'
            "
          echo "--- Pipeline Finished ---"

      - name: Verify Model Outputs
        if: always()
        run: |
          echo "--- Checking Generated Models ---"
          ls -la models/ || echo "No models directory"
          if [ -f 'models/student_quant_int8.tflite' ]; then
            echo "✅ TFLite model generated successfully"
            ls -lh models/student_quant_int8.tflite
          else
            echo "❌ TFLite model missing"
          fi
          
          if [ -f 'models/best_student.pth' ]; then
            echo "✅ PyTorch model generated successfully" 
            ls -lh models/best_student.pth
          else
            echo "❌ PyTorch model missing"
          fi

      - name: Upload MLflow Logs Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-logs
          path: mlruns/
          retention-days: 7

      - name: Upload Model Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trained-models
          path: models/
          retention-days: 7

      - name: Upload DVC Cache Debug
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: dvc-debug
          path: |
            .dvc/
            data/
          retention-days: 3

  # Optional: Add a test job to validate the generated models
  model_validation:
    runs-on: ubuntu-latest
    needs: run_full_mlops_pipeline
    if: success()
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        
      - name: Download Model Artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models
          path: models/
          
      - name: Validate Model Files
        run: |
          echo "--- Validating Generated Models ---"
          
          # Check if required model files exist
          REQUIRED_FILES=(
            "models/student_quant_int8.tflite"
            "models/best_student.pth" 
            "models/pill_db.index"
            "models/labels.json"
            "models/model_metadata.json"
          )
          
          for file in \"${REQUIRED_FILES[@]}\"; do
            if [ -f \"$file\" ]; then
              echo \"✅ $file exists\"
              ls -lh \"$file\"
            else
              echo \"❌ $file missing\"
            fi
          done
          
          echo "--- Model Validation Complete ---"