name: MLOps Production Pipeline (Train, Convert, Deploy)

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  run_full_mlops_pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    env:
      IMAGE_NAME: pilltrack-ci-runner
      
    steps:
      - name: Checkout Repository Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup DVC
        uses: iterative/setup-dvc@v1
        with:
          version: 3.0.0

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-1

      - name: Build MLOps Environment Container
        run: |
          docker build -t $IMAGE_NAME -f DockerFile .
          echo "‚úÖ Docker image built successfully"

      - name: Run DVC Repro Pipeline
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          AWS_DEFAULT_REGION: ap-southeast-1 
        run: |
          echo "--- Starting Pipeline Execution inside Docker ---"
          
          # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå necessary ‡∏Å‡πà‡∏≠‡∏ô
          mkdir -p data/raw models mlruns
          
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e MLFLOW_TRACKING_URI \
            -e S3_BUCKET_NAME \
            -e AWS_DEFAULT_REGION \
            --user $(id -u):$(id -g) \
            $IMAGE_NAME \
            /bin/bash -c "
              set -e  # Exit on error
              
              echo '=== Current Directory Structure ==='
              pwd
              ls -la
              
              echo '=== Checking DVC Configuration ==='
              dvc version
              dvc remote list
              
              echo '=== Available DVC Files ==='
              find . -name '*.dvc' -type f
              
              echo '=== Data Directory Before DVC Pull ==='
              ls -la data/
              
              echo '=== Force Pulling Dataset ==='
              # ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏•‡∏ö cache directory ‡πÅ‡∏ó‡∏ô dvc cache clear
              rm -rf .dvc/cache
              
              # Force pull dataset ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
              dvc pull data/pills_dataset_resnet.zip.dvc -f
              
              echo '=== Checking Dataset After Force Pull ==='
              if [ -f 'data/pills_dataset_resnet.zip' ]; then
                echo '‚úÖ Dataset zip file found'
                ls -lh data/pills_dataset_resnet.zip
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå zip ‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢
                echo '=== Validating Zip File ==='
                if unzip -t data/pills_dataset_resnet.zip > /dev/null 2>&1; then
                  echo '‚úÖ Zip file is valid'
                else
                  echo '‚ùå Zip file is corrupted'
                  exit 1
                fi
              else
                echo '‚ùå Dataset still missing, checking DVC status...'
                dvc status
                echo '=== Debug: DVC Files Content ==='
                cat data/pills_dataset_resnet.zip.dvc
                echo '=== Debug: DVC Lock File ==='
                cat dvc.lock | grep -A 5 -B 5 pills_dataset || echo 'Not found in lock file'
                exit 1
              fi
              
              # ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏ú‡∏¥‡∏î
              echo '=== Cleaning Old Models ==='
              rm -rf models/*
              
              echo '=== Running Pipeline ==='
              dvc status
              dvc repro -v
              
              echo '=== Checking Pipeline Outputs ==='
              echo 'Models generated:'
              ls -la models/
              
              # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á
              REQUIRED_MODELS=(
                'models/best_student.pth'
                'models/student_quant_int8.tflite' 
                'models/pill_db.index'
                'models/labels.json'
                'models/model_metadata.json'
              )
              
              for model in \"${REQUIRED_MODELS[@]}\"; do
                if [ -f \"$model\" ]; then
                  echo \"‚úÖ $model generated successfully\"
                  ls -lh \"$model\"
                else
                  echo \"‚ùå $model missing\"
                  exit 1
                fi
              done
              
              echo '=== Pushing Results ==='
              dvc push -v
              
              echo '‚úÖ Pipeline completed successfully!'
            "
          echo "--- Pipeline Finished ---"

      - name: Verify Model Outputs
        if: always()
        run: |
          echo "--- Checking Generated Models ---"
          ls -la models/ || echo "No models directory"
          if [ -f 'models/student_quant_int8.tflite' ]; then
            echo "‚úÖ TFLite model generated successfully"
            ls -lh models/student_quant_int8.tflite
          else
            echo "‚ùå TFLite model missing"
          fi
          
          if [ -f 'models/best_student.pth' ]; then
            echo "‚úÖ PyTorch model generated successfully" 
            ls -lh models/best_student.pth
          else
            echo "‚ùå PyTorch model missing"
          fi

      - name: Upload MLflow Logs Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-logs
          path: mlruns/
          retention-days: 7

      - name: Upload Model Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trained-models
          path: models/
          retention-days: 7

      - name: Upload DVC Debug Info
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: dvc-debug-info
          path: |
            .dvc/
            data/
            dvc.lock
            dvc.yaml
          retention-days: 3

  # Optional: Model validation job
  model_validation:
    runs-on: ubuntu-latest
    needs: run_full_mlops_pipeline
    if: success()
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        
      - name: Download Model Artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models
          path: models/
          
      - name: Validate Model Files
        run: |
          echo "--- Validating Generated Models ---"
          
          REQUIRED_FILES=(
            "models/student_quant_int8.tflite"
            "models/best_student.pth" 
            "models/pill_db.index"
            "models/labels.json"
            "models/model_metadata.json"
          )
          
          ALL_PASSED=true
          for file in \"${REQUIRED_FILES[@]}\"; do
            if [ -f \"$file\" ]; then
              echo \"‚úÖ $file exists ($(stat -c%s \"$file\") bytes)\"
            else
              echo \"‚ùå $file missing\"
              ALL_PASSED=false
            fi
          done
          
          if [ \"$ALL_PASSED\" = true ]; then
            echo \"üéâ All models validated successfully!\"
          else
            echo \"üí• Some models are missing\"
            exit 1
          fi